{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 4.137241\n",
      "Epoch 100, Loss 3.641506\n",
      "Epoch 200, Loss 3.224977\n",
      "Epoch 300, Loss 2.936230\n",
      "Epoch 400, Loss 2.719201\n",
      "Epoch 500, Loss 2.537468\n",
      "Epoch 600, Loss 2.369702\n",
      "Epoch 700, Loss 2.233190\n",
      "Epoch 800, Loss 2.106858\n",
      "Epoch 900, Loss 1.984220\n"
     ]
    }
   ],
   "source": [
    "device='cuda'\n",
    "\n",
    "\n",
    "# Take ρ(x) = tanh(x). Consider the 1-hidden layer neural network\n",
    "# ŷ i = w 2 T ρ(W 1 x i + b 1 ) + b 2\n",
    "# W is 20 × 10 and w 2 is a vector of size 20. x is a vector of size 10. b 1 and b 2 are vectors of size 20 and 1 respectively.\n",
    "\n",
    "# Define the parameters\n",
    "param_dict = {\n",
    "    'W1': torch.randn(20, 10, device=device, requires_grad=True),\n",
    "    'b1': torch.randn(10, device=device, requires_grad=True),\n",
    "    'W2': torch.randn(20, device=device, requires_grad=True),\n",
    "    'b2': torch.randn(10, device=device, requires_grad=True)\n",
    "}   \n",
    "\n",
    "\n",
    "# Define the network\n",
    "def my_nn(input, param_dict):\n",
    "\n",
    "    x = input.view(-1 , 10) \n",
    "    \n",
    "    tanh = torch.nn.Tanh()\n",
    "\n",
    "    x = torch.matmul(param_dict['W1'], x) + param_dict['b1']\n",
    "\n",
    "    x = tanh(x)\n",
    "    \n",
    "    x = torch.matmul(param_dict['W2'],x ) + param_dict['b2']\n",
    "\n",
    "    return x\n",
    "\n",
    "# The\n",
    "# absolute loss given\n",
    "# l(ŷ, y) = |ŷ − y|\n",
    "# Consider the cost function J = 1/N ∑ i=1 l(ŷ , y )\n",
    "# Derive an expression for\n",
    "# ∂J/∂W1,∂J/∂W2,∂J/∂b1,∂J/∂b2\n",
    "# and implement it in PyTorch.\n",
    "\n",
    "# Define the loss function\n",
    "def my_loss(y_hat, y):\n",
    "    return torch.mean(torch.abs(y_hat - y))\n",
    "\n",
    "# Define the training loop\n",
    "def train_loop(param_dict, input, target, num_epochs=1000, learning_rate=1e-3):\n",
    "    for epoch in range(num_epochs):\n",
    "        y_hat = my_nn(input, param_dict)\n",
    "        loss = my_loss(y_hat, target)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for param in param_dict.values():\n",
    "                param -= learning_rate * param.grad\n",
    "                param.grad.zero_()\n",
    "        if epoch % 100 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return param_dict\n",
    "\n",
    "# Generate some random data\n",
    "input = torch.randn(10, 10, device=device)\n",
    "target = torch.randn(10, 10, device=device)\n",
    "\n",
    "# Train the network\n",
    "param_dict = train_loop(param_dict, input, target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "500c0e9a6935d00759d77722fd6506f0833ee64cfb01e602cf0f077fa4be4564"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
